
In the previous section, we discussed the rejection sampling and importance sampling strategies for evaluating expectations of functions, and we saw that they suffer
from severe limitations particularly in spaces of high dimensionality. We therefore
turn in this section to a very general and powerful framework called Markov chain
Monte Carlo (MCMC), which allows sampling from a large class of distributions,


-----

and which scales well with the dimensionality of the sample space. Markov chain
Monte Carlo methods have their origins in physics (Metropolis and Ulam, 1949),
and it was only towards the end of the 1980s that they started to have a significant
impact in the field of statistics.
As with rejection and importance sampling, we again sample from a proposal
distribution. This time, however, we maintain a record of the current state z[(][τ] [)], and
the proposal distribution q(z **z[(][τ]** [)]) depends on this current state, and so the sequence
_|_
_Section 11.2.1_ of samples z[(1)], z[(2)], . . . forms a Markov chain. Again, if we write p(z) = �p(z)/Zp,

we will assume that _p(z) can readily be evaluated for any given value of z, although_
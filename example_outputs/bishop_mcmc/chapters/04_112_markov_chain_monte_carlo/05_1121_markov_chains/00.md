
Before discussing Markov chain Monte Carlo methods in more detail, it is useful to study some general properties of Markov chains in more detail. In particular,
we ask under what circumstances will a Markov chain converge to the desired distribution. A first-order Markov chain is defined to be a series of random variables
**z[(1)], . . ., z[(][M]** [)] such that the following conditional independence property holds for
_m_ 1, . . ., M 1
_∈{_ _−_ _}_

_p(z[(][m][+1)]_ **z[(1)], . . ., z[(][m][)]) = p(z[(][m][+1)]** **z[(][m][)]).** (11.37)
_|_ _|_

This of course can be represented as a directed graph in the form of a chain, an example of which is shown in Figure 8.38. We can then specify the Markov chain by
giving the probability distribution for the initial variable p(z[(0)]) together with the


-----

conditional probabilities for subsequent variables in the form of transition probabil_ities Tm(z[(][m][)], z[(][m][+1)]) ≡_ _p(z[(][m][+1)]|z[(][m][)]). A Markov chain is called homogeneous_
if the transition probabilities are the same for all m.
The marginal probability for a particular variable can be expressed in terms of
the marginal probability for the previous variable in the chain in the form


_p[⋆](z[′])T_ (z[′], z) = _p[⋆](z)T_ (z, z[′]) = p[⋆](z) _p(z[′]_ **z) = p[⋆](z).** (11.41)

_|_

**z[′]** **z[′]** **z[′]**

A Markov chain that respects detailed balance is said to be reversible.
Our goal is to use Markov chains to sample from a given distribution. We can
achieve this if we set up a Markov chain such that the desired distribution is invariant.
However, we must also require that for m, the distribution p(z[(][m][)]) converges
_→∞_
to the required invariant distribution p[⋆](z), irrespective of the choice of initial distribution p(z[(0)]). This property is called ergodicity, and the invariant distribution
is then called the equilibrium distribution. Clearly, an ergodic Markov chain can
have only one equilibrium distribution. It can be shown that a homogeneous Markov
chain will be ergodic, subject only to weak restrictions on the invariant distribution
and the transition probabilities (Neal, 1993).
In practice we often construct the transition probabilities from a set of ‘base’
transitions B1, . . ., BK. This can be achieved through a mixture distribution of the
form

_K_
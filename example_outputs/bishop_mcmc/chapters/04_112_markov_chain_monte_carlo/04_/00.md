_._ (11.33)


This can be achieved by choosing a random number u with uniform distribution over
the unit interval (0, 1) and then accepting the sample if A(z[⋆], z[(][τ] [)]) > u. Note that
if the step from z[(][τ] [)] to z[⋆] causes an increase in the value of p(z), then the candidate
point is certain to be kept.
If the candidate sample is accepted, then z[(][τ] [+1)] = z[⋆], otherwise the candidate
point z[⋆] is discarded, z[(][τ] [+1)] is set to z[(][τ] [)] and another candidate sample is drawn
from the distribution q(z **z[(][τ]** [+1)]). This is in contrast to rejection sampling, where re_|_
jected samples are simply discarded. In the Metropolis algorithm when a candidate
point is rejected, the previous sample is included instead in the final list of samples,
leading to multiple copies of samples. Of course, in a practical implementation,
only a single copy of each retained sample would be kept, along with an integer
weighting factor recording how many times that state appears. As we shall see, as
long as q(zA|zB) is positive for any values of zA and zB (this is a sufficient but
not necessary condition), the distribution of z[(][τ] [)] tends to p(z) as τ . It should
_→∞_
be emphasized, however, that the sequence z[(1)], z[(2)], . . . is not a set of independent
samples from p(z) because successive samples are highly correlated. If we wish to
obtain independent samples, then we can discard most of the sequence and just retain every M [th] sample. For M sufficiently large, the retained samples will for all
practical purposes be independent. Figure 11.9 shows a simple illustrative example of sampling from a two-dimensional Gaussian distribution using the Metropolis
algorithm in which the proposal distribution is an isotropic Gaussian.
Further insight into the nature of Markov chain Monte Carlo algorithms can be
gleaned by looking at the properties of a specific example, namely a simple random


-----

**Figure 11.9** A simple illustration using Metropo
3

lis algorithm to sample from a
Gaussian distribution whose one
standard-deviation contour is shown

2.5

by the ellipse. The proposal distribution is an isotropic Gaussian distribution whose standard deviation is 2
0.2. Steps that are accepted are
shown as green lines, and rejected
steps are shown in red. A total of 1.5
150 candidate samples are generated, of which 43 are rejected.

1

0.5

0
0 0.5 1 1.5 2 2.5 3

walk. Consider a state space z consisting of the integers, with probabilities

_p(z[(][τ]_ [+1)] = z[(][τ] [)]) = 0.5 (11.34)

_p(z[(][τ]_ [+1)] = z[(][τ] [)] + 1) = 0.25 (11.35)

_p(z[(][τ]_ [+1)] = z[(][τ] [)] 1) = 0.25 (11.36)
_−_

where z[(][τ] [)] denotes the state at step τ . If the initial state is z[(1)] = 0, then by symmetry the expected state at time τ will also be zero E[z[(][τ] [)]] = 0, and similarly it is
_Exercise 11.10_ easily seen that E[(z[(][τ] [)])[2]] = τ/2. Thus after τ steps, the random walk has only trav
elled a distance that on average is proportional to the square root of τ . This square
root dependence is typical of random walk behaviour and shows that random walks
are very inefficient in exploring the state space. As we shall see, a central goal in
designing Markov chain Monte Carlo methods is to avoid random walk behaviour.
